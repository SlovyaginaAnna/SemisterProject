{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "R3jBK58YaHS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from PIL import Image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "BATCH_SIZE=24\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
        "NUM_WORKERS=int(os.cpu_count() / 2)"
      ],
      "metadata": {
        "id": "YrypwS8jaP4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "Kdgi65L3cFxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.load(\"/content/gdrive/MyDrive/small_data.npy\")"
      ],
      "metadata": {
        "id": "IuTSGuVPajkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.genfromtxt('/content/gdrive/MyDrive/all_target.csv', delimiter=',')\n",
        "labels = labels[1:]\n",
        "label = np.zeros(81*10)\n",
        "labels = np.array([1 if i < 3 else 0 for i in labels]) #1 - healthy | 0 - problems\n",
        "for i in range(810):\n",
        "  label[i] = labels[i//10]\n",
        "label = label.astype(int,copy=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "OqAprl2RcyPq",
        "outputId": "c7f449b4-25a0-482f-9ed5-b2e38b967733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4f70fa7ad531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/all_target.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1 - healthy | 0 - problems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape\n",
        "images = np.resize(images, (810, 512, 512))"
      ],
      "metadata": {
        "id": "LB4qQIwzcZP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = images[:700, :, :]\n",
        "train_labels = label[:700]\n",
        "test_images = images[700 :, :, :]\n",
        "test_labels = label[700:]"
      ],
      "metadata": {
        "id": "h3L61Q5DcbZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import albumentations.pytorch\n",
        "\n",
        "\n",
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, transforms):\n",
        "        self.images = train_images\n",
        "        self.labels = train_labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        img = img[130:430, 100:400]\n",
        "        augmentations = self.transforms(image=img)\n",
        "        image = augmentations[\"image\"]\n",
        "        return image, (self.labels[idx].astype(np.float32))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]"
      ],
      "metadata": {
        "id": "1RnQvTNfjxhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, transforms):\n",
        "        self.images = test_images\n",
        "        self.labels = test_labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        img = img[130:430, 100:400]\n",
        "        augmentations = self.transforms(image=img)\n",
        "        image = augmentations[\"image\"]\n",
        "        return image, (self.labels[idx].astype(int))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]"
      ],
      "metadata": {
        "id": "Lw5aByUncfBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = SegmentationTestDataset(\n",
        "    transforms=A.Compose([A.Resize(height=128, width=128),A.Normalize((0.5,), (0.5,)), A.pytorch.transforms.ToTensorV2()]),\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_data, batch_size=110, pin_memory=True, num_workers=3, shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "LWE1LX-dci18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "id": "r-dKUiqvckpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = SegmentationDataset(\n",
        "    transforms=A.Compose([A.Resize(height=128, width=128),A.Normalize((0.5,), (0.5,)), A.pytorch.transforms.ToTensorV2()]),\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=data, batch_size=BATCH_SIZE, pin_memory=True, num_workers=3, shuffle = True\n",
        ")"
      ],
      "metadata": {
        "id": "XJ2fTprOcmWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def im_show(img_list) -> None:\n",
        "\n",
        "    fig, axes = plt.subplots(len(img_list), 1, figsize=(16, 16))\n",
        "    fig.tight_layout()\n",
        "\n",
        "    for (idx, sample) in enumerate(img_list):\n",
        "        a = axes[idx].imshow(sample.squeeze())\n",
        "        for ax in axes:\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "img_list = []\n",
        "for i in range(4):\n",
        "    img = data[i][0]\n",
        "    img_list.append(img)\n",
        "\n",
        "im_show(img_list)"
      ],
      "metadata": {
        "id": "iB1NzL-Icofs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание модели данных"
      ],
      "metadata": {
        "id": "fx_igr9Scq2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 48, 4, 2, 1),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(48, 4, 4, 3),\n",
        "            nn.BatchNorm2d(4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(4*21*21, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img #.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "\n",
        "        return validity"
      ],
      "metadata": {
        "id": "VtRZHzVPcsw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Discriminator((1, 128, 128)))"
      ],
      "metadata": {
        "id": "IeDGgif7cut2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        super().__init__()\n",
        "        self.img_shape = img_shape\n",
        "\n",
        "        def block(in_ch, out_ch, kernel_size, stride, padding, normalize=True, relu = True):\n",
        "            layers = [nn.ConvTranspose2d(in_channels = in_ch, out_channels = out_ch,\n",
        "                                         kernel_size = kernel_size, stride = stride,\n",
        "                                         padding = padding)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_ch, 0.8))\n",
        "            if relu: \n",
        "              layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(latent_dim, 128, 8, 2, 0),\n",
        "            *block(128, 256, 4, 3, 2),\n",
        "            *block(256, 48, 4, 3, 0),\n",
        "            *block(48, 1, 4, 2, 1, False, False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        inp = z.view(z.size(0), z.size(1), 1, 1)\n",
        "        img = self.model(inp)\n",
        "        return img"
      ],
      "metadata": {
        "id": "XUT29CRJcxpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Generator(100, (1, 128, 128)))"
      ],
      "metadata": {
        "id": "3K4zb66Vczg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "discr_loss_trace = []\n",
        "gen_loss_trace = []\n",
        "test_acc = []"
      ],
      "metadata": {
        "id": "taE14mT0c13X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S1 = [[1, 2, 0],\n",
        " [3, 4, 1],\n",
        " [5, 6, 2],\n",
        " [4, 6, 7],\n",
        " [9, 10, 8],\n",
        " [10, 11, 13],\n",
        " [12, 9, 14],\n",
        " [14, 13, 15]]\n",
        " S2 = [[0, 15], [12, 3], [11, 5], [7, 8]]"
      ],
      "metadata": {
        "id": "rvj2jrwndpMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "U0CabGrQc4vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fitter(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        batch_size = 32,\n",
        "        n_epochs = 10,\n",
        "        latent_dim = 1,\n",
        "        lr = 0.0001,\n",
        "        n_critic=5,\n",
        "    ):\n",
        "\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.batch_size = batch_size\n",
        "        self.n_epochs = n_epochs\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lr = lr\n",
        "        self.n_critic = n_critic\n",
        "\n",
        "        self.opt_gen = torch.optim.Adam(self.generator.parameters(), lr=self.lr)\n",
        "        self.opt_disc = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr)\n",
        "\n",
        "        self.generator.to(DEVICE)\n",
        "        self.discriminator.to(DEVICE)\n",
        "\n",
        "    def fit(self, train_dataloader):\n",
        "\n",
        "        # Turn on training\n",
        "        self.generator.train(True)\n",
        "        self.discriminator.train(True)\n",
        "\n",
        "        self.loss_history = []\n",
        "\n",
        "        # Fit GAN\n",
        "        i = 0\n",
        "        for epoch in tqdm(range(self.n_epochs)):\n",
        "            start = time.time()\n",
        "            for real_batch in train_dataloader:\n",
        "                real_objects, real_labels = real_batch\n",
        "                real_labels = real_labels.to(DEVICE)\n",
        "                real_objects = real_objects.to(DEVICE)\n",
        "                real_labels = torch.unsqueeze(real_labels, 1)\n",
        "                \n",
        "                num_objects = real_objects.shape[0]\n",
        "                z = torch.normal(0, 1, (len(real_objects), self.latent_dim))\n",
        "                gen_objects = self.generator(z)\n",
        "                \n",
        "                real_objects_scores = self.discriminator(real_objects)\n",
        "                gen_objects_scores = self.discriminator(gen_objects)\n",
        "                \n",
        "                for p in self.discriminator.parameters():\n",
        "                    p.data.clamp_(-0.01, 0.01)\n",
        "                if i % (self.n_critic + 1) == 0:\n",
        "                    self.opt_gen.zero_grad()\n",
        "                    valid = torch.ones(real_objects.size(0), 1)\n",
        "                    gen_loss = F.binary_cross_entropy(self.discriminator(self.generator(z)), valid)\n",
        "                    gen_loss.backward()\n",
        "                    self.opt_gen.step()\n",
        "                    gen_loss_trace.append(gen_loss.item())\n",
        "                else:\n",
        "                    self.opt_disc.zero_grad()\n",
        "                    #valid = torch.ones(real_objects.size(0), 1)\n",
        "                    real_loss = F.binary_cross_entropy(self.discriminator(real_objects), real_labels)\n",
        "                    fake = torch.zeros(real_objects.size(0), 1)\n",
        "                    fake_loss = F.binary_cross_entropy(self.discriminator(self.generator(z).detach()), fake)\n",
        "                    discr_loss = (real_loss + fake_loss) / 2\n",
        "                    discr_loss.backward()\n",
        "                    self.opt_disc.step()\n",
        "                    discr_loss_trace.append(discr_loss.item())\n",
        "                i += 1\n",
        "\n",
        "\n",
        "            # caiculate and store loss after an epoch\n",
        "            #Z_noise = torch.normal(0, 1, (len(X_real), self.latent_dim))\n",
        "            #X_fake = self.generator(Z_noise)\n",
        "            #loss_epoch = torch.mean(self.discriminator(X_real)) - torch.mean(\n",
        "             #   self.discriminator(X_fake)\n",
        "            #)\n",
        "            #self.loss_history.append(loss_epoch.detach().cpu())\n",
        "\n",
        "            # Валидация\n",
        "            self.generator.train(False)\n",
        "            self.discriminator.train(False)\n",
        "\n",
        "            for valid_batch in test_loader:\n",
        "              valid_objects, valid_labels = valid_batch\n",
        "              valid_labels = valid_labels.to(DEVICE)\n",
        "              valid_objects = valid_objects.to(DEVICE)\n",
        "              valid_labels = torch.unsqueeze(valid_labels, 1)\n",
        "              z = torch.normal(0, 1, (30, self.latent_dim))\n",
        "              gen_objects = self.generator(z)\n",
        "              real_objects_scores = self.discriminator(valid_objects)\n",
        "              gen_objects_scores = self.discriminator(gen_objects)\n",
        "              #print(real_objects_scores.size(), gen_objects_scores.size(), valid_labels.size())\n",
        "              y_pr = torch.cat([real_objects_scores, gen_objects_scores], 0)\n",
        "              y_tr = torch.cat([valid_labels, torch.zeros((30, 1))], 0)\n",
        "              y_pred = torch.squeeze(y_pr, 1)\n",
        "              y_true = torch.squeeze(y_tr, 1)\n",
        "              y_pred = torch.tensor([0 if i < 0.5 else 1 for i in y_pred.detach().numpy()])\n",
        "              acc = accuracy_score(y_pred, y_true)\n",
        "              test_acc.append(acc)\n",
        "\n",
        "            if epoch % 50 == 0:\n",
        "              path_gen = \"model_gen_\"+ str(epoch)\n",
        "              torch.save(self.generator, path_gen)\n",
        "              path_disc = \"model_disc_\" + str(epoch)\n",
        "              torch.save(self.discriminator, path_disc)\n",
        "            self.generator.train(True)\n",
        "            self.discriminator.train(True)\n",
        "            print ('Time for epoch {} is {} sec'.format(epoch, time.time()-start))\n",
        "\n",
        "            \n",
        "        # Turn off training\n",
        "        self.generator.train(False)\n",
        "        self.discriminator.train(False)"
      ],
      "metadata": {
        "id": "KYUPSYtEc7S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "data_shape = (1, 128, 128)\n",
        "generator = Generator(latent_dim=latent_dim, img_shape=data_shape)\n",
        "discriminator = Discriminator(img_shape=data_shape)\n",
        "\n",
        "fitter = Fitter(\n",
        "    generator,\n",
        "    discriminator,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    n_epochs=500,\n",
        "    latent_dim=latent_dim,\n",
        "    lr=0.0001,\n",
        "    n_critic=3,\n",
        ")\n",
        "fitter.fit(train_loader)"
      ],
      "metadata": {
        "id": "o8X2xZcxc-kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Generator loss\")\n",
        "plt.plot(range(len(gen_loss_trace)), gen_loss_trace)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Discriminator loss\")\n",
        "plt.plot(range(len(discr_loss_trace)), discr_loss_trace, color=\"orange\")"
      ],
      "metadata": {
        "id": "mhLX5TmUdAvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Test accuracy\")\n",
        "plt.plot(range(len(test_acc)), test_acc)"
      ],
      "metadata": {
        "id": "LQNoNhN1dDm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.normal(0, 1, (2, 100))\n",
        "images = generator(z).detach().numpy()\n",
        "im_show(images)"
      ],
      "metadata": {
        "id": "LOyQiEDqdGRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}